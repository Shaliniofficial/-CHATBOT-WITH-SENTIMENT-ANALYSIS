{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PguHwiIEiyW",
        "outputId": "ebcf9692-ddc6-4cd6-ccec-42220357d2ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install colorama"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries**"
      ],
      "metadata": {
        "id": "dpauTPEK6d-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "from dataclasses import dataclass, asdict\n",
        "import random\n",
        "import os\n",
        "\n",
        "# For colored output in terminal\n",
        "try:\n",
        "    from colorama import Fore, Style, init\n",
        "    init(autoreset=True)\n",
        "    COLORS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    COLORS_AVAILABLE = False\n",
        "    print(\"Note: Install colorama for colored output: pip install colorama\")\n"
      ],
      "metadata": {
        "id": "JNUSnYPvE2wW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Models**"
      ],
      "metadata": {
        "id": "LgSV5Wrk6xls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA MODELS\n",
        "# ===================================================================\n",
        "\n",
        "@dataclass\n",
        "class SentimentResult:\n",
        "    \"\"\"Data class for sentiment analysis results\"\"\"\n",
        "    label: str  # 'Positive', 'Negative', 'Neutral'\n",
        "    score: float\n",
        "    confidence: float\n",
        "\n",
        "    def to_dict(self):\n",
        "        return asdict(self)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Message:\n",
        "    \"\"\"Data class for conversation messages\"\"\"\n",
        "    id: str\n",
        "    type: str  # 'user' or 'bot'\n",
        "    text: str\n",
        "    timestamp: str\n",
        "    sentiment: Optional[SentimentResult] = None\n",
        "\n",
        "    def to_dict(self):\n",
        "        data = asdict(self)\n",
        "        if self.sentiment:\n",
        "            data['sentiment'] = self.sentiment.to_dict()\n",
        "        return data\n",
        "\n"
      ],
      "metadata": {
        "id": "6u-dFqgME-RO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SENTIMENT ANALYZER**"
      ],
      "metadata": {
        "id": "3F3T-Fug63VB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SENTIMENT ANALYZER (Production-Ready)\n",
        "# ===================================================================\n",
        "\n",
        "class RuleBasedSentimentAnalyzer:\n",
        "    \"\"\"\n",
        "    Advanced rule-based sentiment analyzer\n",
        "    Production-ready with extensive word lists and scoring logic\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Comprehensive positive word list\n",
        "        self.positive_words = {\n",
        "            'good', 'great', 'excellent', 'happy', 'love', 'wonderful',\n",
        "            'fantastic', 'amazing', 'better', 'best', 'thank', 'thanks',\n",
        "            'pleased', 'satisfied', 'awesome', 'brilliant', 'superb',\n",
        "            'outstanding', 'perfect', 'delighted', 'appreciated', 'impressive',\n",
        "            'enjoyable', 'favorable', 'positive', 'successful', 'helpful',\n",
        "            'efficient', 'reliable', 'quality', 'superior', 'recommend',\n",
        "            'exceptional', 'spectacular', 'marvelous', 'fabulous', 'nice',\n",
        "            'beautiful', 'lovely', 'terrific', 'splendid', 'magnificent',\n",
        "            'glad', 'joy', 'pleased', 'cheerful', 'excited', 'thrilled'\n",
        "        }\n",
        "\n",
        "        # Comprehensive negative word list\n",
        "        self.negative_words = {\n",
        "            'bad', 'terrible', 'horrible', 'hate', 'worst', 'poor',\n",
        "            'disappoints', 'disappointed', 'awful', 'sad', 'angry',\n",
        "            'frustrate', 'frustrated', 'dissatisfied', 'unhappy', 'useless',\n",
        "            'annoying', 'annoyed', 'pathetic', 'disgusting', 'unacceptable',\n",
        "            'failure', 'failed', 'problem', 'issue', 'error', 'wrong',\n",
        "            'broken', 'slow', 'difficult', 'confusing', 'waste', 'nasty',\n",
        "            'dreadful', 'inferior', 'lousy', 'mediocre', 'unfortunate',\n",
        "            'upset', 'concern', 'worried', 'trouble', 'complaint'\n",
        "        }\n",
        "\n",
        "        self.intensifiers = {'very', 'extremely', 'highly', 'absolutely', 'really', 'so', 'too', 'quite'}\n",
        "        self.negations = {'not', 'no', 'never', 'neither', 'nobody', 'nothing', \"n't\", 'dont', \"don't\"}\n",
        "\n",
        "    def analyze(self, text: str) -> SentimentResult:\n",
        "        \"\"\"\n",
        "        Analyze sentiment of text using advanced rule-based approach\n",
        "        \"\"\"\n",
        "        if not text or not text.strip():\n",
        "            return SentimentResult(label='Neutral', score=0.0, confidence=0.5)\n",
        "\n",
        "        text_lower = text.lower()\n",
        "        words = text_lower.split()\n",
        "\n",
        "        score = 0.0\n",
        "        matched_words = 0\n",
        "\n",
        "        # Check for negations\n",
        "        has_negation = any(neg in text_lower for neg in self.negations)\n",
        "        negation_multiplier = -0.8 if has_negation else 1.0\n",
        "\n",
        "        # Check for intensifiers\n",
        "        has_intensifier = any(intensifier in text_lower for intensifier in self.intensifiers)\n",
        "        intensity_boost = 1.5 if has_intensifier else 1.0\n",
        "\n",
        "        # Score positive words\n",
        "        for word in self.positive_words:\n",
        "            if word in text_lower:\n",
        "                weight = intensity_boost\n",
        "                score += weight * negation_multiplier\n",
        "                matched_words += 1\n",
        "\n",
        "        # Score negative words\n",
        "        for word in self.negative_words:\n",
        "            if word in text_lower:\n",
        "                weight = intensity_boost\n",
        "                score -= weight * negation_multiplier\n",
        "                matched_words += 1\n",
        "\n",
        "        # Punctuation analysis\n",
        "        if '!' in text:\n",
        "            score = score * 1.2 if score != 0 else score\n",
        "\n",
        "        # Calculate confidence\n",
        "        base_confidence = 0.5\n",
        "        word_confidence = min(matched_words * 0.15, 0.4)\n",
        "        confidence = min(base_confidence + word_confidence, 0.95)\n",
        "\n",
        "        # Determine sentiment label\n",
        "        if score > 0.5:\n",
        "            label = 'Positive'\n",
        "        elif score < -0.5:\n",
        "            label = 'Negative'\n",
        "        else:\n",
        "            label = 'Neutral'\n",
        "\n",
        "        return SentimentResult(label=label, score=round(score, 2), confidence=round(confidence, 2))\n",
        "\n"
      ],
      "metadata": {
        "id": "4QRRVBhGFCoi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMART RESPONSE GENERATOR**"
      ],
      "metadata": {
        "id": "2RAzFYYo7YOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# SMART RESPONSE GENERATOR\n",
        "# ===================================================================\n",
        "\n",
        "class SmartResponseGenerator:\n",
        "    \"\"\"\n",
        "    Smart response generator with context awareness and sentiment analysis\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.base_responses = {\n",
        "            'Positive': [\n",
        "                \"I'm glad to hear that! How can I assist you further?\",\n",
        "                \"That's wonderful! What else can I help you with?\",\n",
        "                \"Great to hear! Let me know if there's anything more I can do.\",\n",
        "                \"I appreciate your positive feedback! How may I continue helping?\",\n",
        "                \"Thank you for sharing! I'm here to support you with anything else you need.\",\n",
        "                \"Excellent! Your satisfaction is important to me. What's next?\"\n",
        "            ],\n",
        "            'Negative': [\n",
        "                \"I understand your concern. Let me help address this issue.\",\n",
        "                \"I'm sorry to hear that. I'll make sure your concern is addressed.\",\n",
        "                \"I apologize for the inconvenience. How can I make this better?\",\n",
        "                \"I hear you, and I want to help resolve this for you.\",\n",
        "                \"I understand this is frustrating. Let's work together to find a solution.\",\n",
        "                \"Your feedback is valuable. Let me see how I can help improve your experience.\"\n",
        "            ],\n",
        "            'Neutral': [\n",
        "                \"I see. How can I assist you today?\",\n",
        "                \"Understood. What would you like to know?\",\n",
        "                \"Got it. What can I help you with?\",\n",
        "                \"I'm here to help. What do you need?\",\n",
        "                \"Thank you for sharing. How may I assist you?\",\n",
        "                \"I'm listening. How can I support you today?\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Keyword-based contextual responses\n",
        "        self.contextual_templates = {\n",
        "            'price': {\n",
        "                'Positive': \"I'm glad the pricing works for you! Would you like to know more about the features included?\",\n",
        "                'Negative': \"I understand pricing is a concern. Let me help you find the best value option for your needs.\",\n",
        "                'Neutral': \"I'd be happy to discuss our pricing options. What specific information would you like?\"\n",
        "            },\n",
        "            'support': {\n",
        "                'Positive': \"Thank you for the positive feedback about our support! Is there anything specific I can help with?\",\n",
        "                'Negative': \"I apologize for any support issues. Your experience matters to us. How can I make this right?\",\n",
        "                'Neutral': \"I'm here to provide support. What can I help you with today?\"\n",
        "            },\n",
        "            'feature': {\n",
        "                'Positive': \"Great! I'm glad you like that feature. Would you like to explore more capabilities?\",\n",
        "                'Negative': \"I understand that feature isn't working as expected. Let me help troubleshoot this.\",\n",
        "                'Neutral': \"I'd be happy to explain that feature in detail. What would you like to know?\"\n",
        "            },\n",
        "            'problem': {\n",
        "                'Positive': \"I'm glad we could resolve that problem! Anything else I can help with?\",\n",
        "                'Negative': \"I understand you're experiencing an issue. Let me help troubleshoot this right away.\",\n",
        "                'Neutral': \"Let me help you with that. Can you describe the problem in more detail?\"\n",
        "            },\n",
        "        }\n",
        "\n",
        "    def detect_keywords(self, text: str) -> List[str]:\n",
        "        \"\"\"Detect relevant keywords in user message\"\"\"\n",
        "        text_lower = text.lower()\n",
        "        detected = []\n",
        "\n",
        "        keyword_groups = {\n",
        "            'price': ['price', 'cost', 'expensive', 'cheap', 'affordable', 'pricing'],\n",
        "            'support': ['support', 'help', 'service', 'assist'],\n",
        "            'feature': ['feature', 'function', 'work', 'how', 'capability'],\n",
        "            'problem': ['problem', 'issue', 'error', 'bug', 'trouble', 'wrong'],\n",
        "        }\n",
        "\n",
        "        for category, keywords in keyword_groups.items():\n",
        "            if any(keyword in text_lower for keyword in keywords):\n",
        "                detected.append(category)\n",
        "\n",
        "        return detected\n",
        "\n",
        "    def generate(self, user_message: str, sentiment: SentimentResult,\n",
        "                 conversation_history: List[Message]) -> str:\n",
        "        \"\"\"Generate smart, contextual response\"\"\"\n",
        "\n",
        "        # Detect keywords\n",
        "        keywords = self.detect_keywords(user_message)\n",
        "\n",
        "        # Try contextual response\n",
        "        if keywords:\n",
        "            primary_keyword = keywords[0]\n",
        "            if primary_keyword in self.contextual_templates:\n",
        "                template_dict = self.contextual_templates[primary_keyword]\n",
        "                return template_dict.get(sentiment.label, random.choice(self.base_responses[sentiment.label]))\n",
        "\n",
        "        # Default to base responses\n",
        "        return random.choice(self.base_responses[sentiment.label])\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# CONVERSATION ANALYZER\n",
        "# ===================================================================\n",
        "\n",
        "class ConversationAnalyzer:\n",
        "    \"\"\"Analyzes entire conversation for sentiment trends\"\"\"\n",
        "\n",
        "    def analyze_conversation(self, messages: List[Message]) -> Dict:\n",
        "        \"\"\"Perform comprehensive conversation-level analysis (TIER 1)\"\"\"\n",
        "        user_messages = [m for m in messages if m.type == 'user' and m.sentiment]\n",
        "\n",
        "        if not user_messages:\n",
        "            return {\n",
        "                'overall_sentiment': 'Neutral',\n",
        "                'description': 'No user messages to analyze',\n",
        "                'total_messages': 0,\n",
        "                'sentiment_counts': {'Positive': 0, 'Negative': 0, 'Neutral': 0},\n",
        "                'average_score': 0.0,\n",
        "                'trend': 'No data',\n",
        "                'sentiment_distribution': {'Positive': 0, 'Negative': 0, 'Neutral': 0}\n",
        "            }\n",
        "\n",
        "        # Calculate metrics\n",
        "        total_score = sum(m.sentiment.score for m in user_messages)\n",
        "        avg_score = total_score / len(user_messages)\n",
        "\n",
        "        sentiment_counts = {\n",
        "            'Positive': sum(1 for m in user_messages if m.sentiment.label == 'Positive'),\n",
        "            'Negative': sum(1 for m in user_messages if m.sentiment.label == 'Negative'),\n",
        "            'Neutral': sum(1 for m in user_messages if m.sentiment.label == 'Neutral')\n",
        "        }\n",
        "\n",
        "        # Calculate percentages\n",
        "        total = len(user_messages)\n",
        "        sentiment_distribution = {\n",
        "            'Positive': round((sentiment_counts['Positive'] / total) * 100, 1),\n",
        "            'Negative': round((sentiment_counts['Negative'] / total) * 100, 1),\n",
        "            'Neutral': round((sentiment_counts['Neutral'] / total) * 100, 1)\n",
        "        }\n",
        "\n",
        "        # Determine overall sentiment\n",
        "        if avg_score > 0.3:\n",
        "            overall_label = 'Positive'\n",
        "            description = 'Generally satisfied and positive tone'\n",
        "        elif avg_score < -0.3:\n",
        "            overall_label = 'Negative'\n",
        "            description = 'General dissatisfaction detected'\n",
        "        else:\n",
        "            overall_label = 'Neutral'\n",
        "            description = 'Balanced conversation'\n",
        "\n",
        "        # Analyze trend\n",
        "        trend = self._analyze_trend(user_messages)\n",
        "\n",
        "        return {\n",
        "            'overall_sentiment': overall_label,\n",
        "            'description': description,\n",
        "            'total_messages': len(user_messages),\n",
        "            'sentiment_counts': sentiment_counts,\n",
        "            'average_score': round(avg_score, 2),\n",
        "            'trend': trend,\n",
        "            'sentiment_distribution': sentiment_distribution\n",
        "        }\n",
        "\n",
        "    def _analyze_trend(self, messages: List[Message]) -> str:\n",
        "        \"\"\"Analyze sentiment trend (TIER 2 ENHANCEMENT)\"\"\"\n",
        "        if len(messages) < 3:\n",
        "            return 'Insufficient data for trend analysis'\n",
        "\n",
        "        mid = len(messages) // 2\n",
        "        first_half = messages[:mid]\n",
        "        second_half = messages[mid:]\n",
        "\n",
        "        first_avg = sum(m.sentiment.score for m in first_half) / len(first_half)\n",
        "        second_avg = sum(m.sentiment.score for m in second_half) / len(second_half)\n",
        "\n",
        "        diff = second_avg - first_avg\n",
        "\n",
        "        if diff > 0.5:\n",
        "            return 'Improving - Sentiment getting more positive'\n",
        "        elif diff < -0.5:\n",
        "            return 'Declining - Sentiment getting more negative'\n",
        "        else:\n",
        "            return 'Stable - Consistent sentiment throughout'\n"
      ],
      "metadata": {
        "id": "CTO_nnByFJjL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CHATBOT**"
      ],
      "metadata": {
        "id": "piWKrMKX7fQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# CHATBOT (Main Controller)\n",
        "# ===================================================================\n",
        "\n",
        "class SentimentChatbot:\n",
        "    \"\"\"Main chatbot class with sentiment-aware responses\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.analyzer = RuleBasedSentimentAnalyzer()\n",
        "        self.response_generator = SmartResponseGenerator()\n",
        "        self.conversation_analyzer = ConversationAnalyzer()\n",
        "        self.messages: List[Message] = []\n",
        "        self.session_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    def process_message(self, user_input: str) -> Tuple[str, SentimentResult]:\n",
        "        \"\"\"Process user message with sentiment analysis\"\"\"\n",
        "        if not user_input or not user_input.strip():\n",
        "            return \"Please enter a message.\", None\n",
        "\n",
        "        # TIER 2: Analyze sentiment for this message\n",
        "        sentiment = self.analyzer.analyze(user_input)\n",
        "\n",
        "        # Create user message\n",
        "        user_msg = Message(\n",
        "            id=f\"user_{len(self.messages)}\",\n",
        "            type='user',\n",
        "            text=user_input,\n",
        "            timestamp=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            sentiment=sentiment\n",
        "        )\n",
        "        self.messages.append(user_msg)\n",
        "\n",
        "        # Generate response based on sentiment\n",
        "        bot_response = self.response_generator.generate(\n",
        "            user_input,\n",
        "            sentiment,\n",
        "            self.messages\n",
        "        )\n",
        "\n",
        "        # Create bot message\n",
        "        bot_msg = Message(\n",
        "            id=f\"bot_{len(self.messages)}\",\n",
        "            type='bot',\n",
        "            text=bot_response,\n",
        "            timestamp=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        )\n",
        "        self.messages.append(bot_msg)\n",
        "\n",
        "        return bot_response, sentiment\n",
        "\n",
        "    def get_conversation_analysis(self) -> Dict:\n",
        "        \"\"\"TIER 1: Get conversation-level sentiment analysis\"\"\"\n",
        "        return self.conversation_analyzer.analyze_conversation(self.messages)\n",
        "\n",
        "    def export_conversation(self, filename: str = None) -> str:\n",
        "        \"\"\"Export conversation to JSON\"\"\"\n",
        "        if filename is None:\n",
        "            filename = f\"conversation_{self.session_id}.json\"\n",
        "\n",
        "        data = {\n",
        "            'session_id': self.session_id,\n",
        "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            'messages': [msg.to_dict() for msg in self.messages],\n",
        "            'analysis': self.get_conversation_analysis()\n",
        "        }\n",
        "\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        return filename\n",
        "\n",
        "    def reset_conversation(self):\n",
        "        \"\"\"Reset conversation\"\"\"\n",
        "        self.messages = []\n",
        "        self.session_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n"
      ],
      "metadata": {
        "id": "FiIo360_FO0-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TERMINAL UI FUNCTIONS**"
      ],
      "metadata": {
        "id": "irN3NtUv7vBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# TERMINAL UI FUNCTIONS\n",
        "# ===================================================================\n",
        "\n",
        "def print_header():\n",
        "    \"\"\"Print chatbot header\"\"\"\n",
        "    if COLORS_AVAILABLE:\n",
        "        print(Fore.CYAN + \"=\" * 70)\n",
        "        print(Fore.CYAN + \"  LiaPlus SENTIMENT ANALYSIS CHATBOT\")\n",
        "        print(Fore.CYAN + \"  Production-Ready Implementation\")\n",
        "        print(Fore.CYAN + \"=\" * 70)\n",
        "        print(Fore.YELLOW + \"\\n‚úì Tier 1: Full conversation sentiment analysis\")\n",
        "        print(Fore.YELLOW + \"‚úì Tier 2: Statement-level sentiment for each message\")\n",
        "        print(Fore.YELLOW + \"‚úì Bonus: Trend analysis & smart responses\")\n",
        "    else:\n",
        "        print(\"=\" * 70)\n",
        "        print(\"  LiaPlus SENTIMENT ANALYSIS CHATBOT\")\n",
        "        print(\"  Production-Ready Implementation\")\n",
        "        print(\"=\" * 70)\n",
        "        print(\"\\n‚úì Tier 1: Full conversation sentiment analysis\")\n",
        "        print(\"‚úì Tier 2: Statement-level sentiment for each message\")\n",
        "        print(\"‚úì Bonus: Trend analysis & smart responses\")\n",
        "\n",
        "    print(\"\\nCommands:\")\n",
        "    print(\"  - Type your message to chat\")\n",
        "    print(\"  - Type 'analysis' to see conversation analysis\")\n",
        "    print(\"  - Type 'history' to see full conversation with sentiments\")\n",
        "    print(\"  - Type 'export' to save conversation\")\n",
        "    print(\"  - Type 'quit' to end conversation\")\n",
        "    print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "\n",
        "def print_sentiment(sentiment: SentimentResult):\n",
        "    \"\"\"Print sentiment analysis\"\"\"\n",
        "    emoji = {'Positive': 'üòä', 'Negative': 'üòû', 'Neutral': 'üòê'}\n",
        "\n",
        "    if COLORS_AVAILABLE:\n",
        "        if sentiment.label == 'Positive':\n",
        "            color = Fore.GREEN\n",
        "        elif sentiment.label == 'Negative':\n",
        "            color = Fore.RED\n",
        "        else:\n",
        "            color = Fore.YELLOW\n",
        "\n",
        "        print(color + f\"\\n‚Üí Sentiment: {emoji[sentiment.label]} {sentiment.label} \" +\n",
        "              f\"(Score: {sentiment.score}, Confidence: {sentiment.confidence})\")\n",
        "    else:\n",
        "        print(f\"\\n‚Üí Sentiment: {emoji[sentiment.label]} {sentiment.label} \" +\n",
        "              f\"(Score: {sentiment.score}, Confidence: {sentiment.confidence})\")\n",
        "\n",
        "\n",
        "def print_analysis(analysis: Dict):\n",
        "    \"\"\"Print conversation analysis (TIER 1)\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üìä OVERALL CONVERSATION ANALYSIS (Tier 1)\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    emoji = {'Positive': 'üòä', 'Negative': 'üòû', 'Neutral': 'üòê'}\n",
        "\n",
        "    if COLORS_AVAILABLE:\n",
        "        print(Fore.CYAN + f\"\\nOverall Sentiment: {emoji[analysis['overall_sentiment']]} {analysis['overall_sentiment']}\")\n",
        "        print(Fore.WHITE + f\"Description: {analysis['description']}\")\n",
        "        print(Fore.WHITE + f\"Total Messages: {analysis['total_messages']}\")\n",
        "        print(Fore.WHITE + f\"Average Score: {analysis['average_score']}\")\n",
        "        print(Fore.WHITE + f\"Sentiment Trend: {analysis['trend']}\")\n",
        "\n",
        "        print(Fore.YELLOW + \"\\nSentiment Distribution:\")\n",
        "        print(Fore.GREEN + f\"  ‚Ä¢ Positive: {analysis['sentiment_counts']['Positive']} ({analysis['sentiment_distribution']['Positive']}%)\")\n",
        "        print(Fore.YELLOW + f\"  ‚Ä¢ Neutral: {analysis['sentiment_counts']['Neutral']} ({analysis['sentiment_distribution']['Neutral']}%)\")\n",
        "        print(Fore.RED + f\"  ‚Ä¢ Negative: {analysis['sentiment_counts']['Negative']} ({analysis['sentiment_distribution']['Negative']}%)\")\n",
        "    else:\n",
        "        print(f\"\\nOverall Sentiment: {emoji[analysis['overall_sentiment']]} {analysis['overall_sentiment']}\")\n",
        "        print(f\"Description: {analysis['description']}\")\n",
        "        print(f\"Total Messages: {analysis['total_messages']}\")\n",
        "        print(f\"Average Score: {analysis['average_score']}\")\n",
        "        print(f\"Sentiment Trend: {analysis['trend']}\")\n",
        "\n",
        "        print(\"\\nSentiment Distribution:\")\n",
        "        print(f\"  ‚Ä¢ Positive: {analysis['sentiment_counts']['Positive']} ({analysis['sentiment_distribution']['Positive']}%)\")\n",
        "        print(f\"  ‚Ä¢ Neutral: {analysis['sentiment_counts']['Neutral']} ({analysis['sentiment_distribution']['Neutral']}%)\")\n",
        "        print(f\"  ‚Ä¢ Negative: {analysis['sentiment_counts']['Negative']} ({analysis['sentiment_distribution']['Negative']}%)\")\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "\n",
        "def print_history(chatbot: SentimentChatbot):\n",
        "    \"\"\"Print full conversation history with sentiments (TIER 2)\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üìú CONVERSATION HISTORY (Tier 2: All Message Sentiments)\")\n",
        "    print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "    for msg in chatbot.messages:\n",
        "        if msg.type == 'user':\n",
        "            if COLORS_AVAILABLE:\n",
        "                print(Fore.CYAN + f\"üë§ User: {msg.text}\")\n",
        "                if msg.sentiment:\n",
        "                    emoji = {'Positive': 'üòä', 'Negative': 'üòû', 'Neutral': 'üòê'}\n",
        "                    print(Fore.YELLOW + f\"   ‚îî‚îÄ Sentiment: {emoji[msg.sentiment.label]} {msg.sentiment.label} (Score: {msg.sentiment.score})\")\n",
        "                print(Fore.WHITE + f\"   ‚îî‚îÄ Time: {msg.timestamp}\\n\")\n",
        "            else:\n",
        "                print(f\"üë§ User: {msg.text}\")\n",
        "                if msg.sentiment:\n",
        "                    emoji = {'Positive': 'üòä', 'Negative': 'üòû', 'Neutral': 'üòê'}\n",
        "                    print(f\"   ‚îî‚îÄ Sentiment: {emoji[msg.sentiment.label]} {msg.sentiment.label} (Score: {msg.sentiment.score})\")\n",
        "                print(f\"   ‚îî‚îÄ Time: {msg.timestamp}\\n\")\n",
        "        else:\n",
        "            if COLORS_AVAILABLE:\n",
        "                print(Fore.GREEN + f\"ü§ñ Bot: {msg.text}\")\n",
        "                print(Fore.WHITE + f\"   ‚îî‚îÄ Time: {msg.timestamp}\\n\")\n",
        "            else:\n",
        "                print(f\"ü§ñ Bot: {msg.text}\")\n",
        "                print(f\"   ‚îî‚îÄ Time: {msg.timestamp}\\n\")\n",
        "\n",
        "    print(\"=\" * 70)\n"
      ],
      "metadata": {
        "id": "99PXHFXCFSqV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# MAIN INTERACTIVE LOOP\n",
        "# ===================================================================\n",
        "\n",
        "def run_chatbot():\n",
        "    \"\"\"Main chatbot interactive loop\"\"\"\n",
        "    print_header()\n",
        "\n",
        "    chatbot = SentimentChatbot()\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n\" + \"-\" * 70)\n",
        "\n",
        "        if COLORS_AVAILABLE:\n",
        "            user_input = input(Fore.CYAN + \"You: \" + Style.RESET_ALL).strip()\n",
        "        else:\n",
        "            user_input = input(\"You: \").strip()\n",
        "\n",
        "        if not user_input:\n",
        "            continue\n",
        "\n",
        "        # Handle commands\n",
        "        if user_input.lower() == 'quit':\n",
        "            print(\"\\nüìä FINAL CONVERSATION ANALYSIS:\")\n",
        "            analysis = chatbot.get_conversation_analysis()\n",
        "            print_analysis(analysis)\n",
        "            print(\"\\n‚úÖ Thank you for using LiaPlus Chatbot!\")\n",
        "            break\n",
        "\n",
        "        elif user_input.lower() == 'analysis':\n",
        "            analysis = chatbot.get_conversation_analysis()\n",
        "            print_analysis(analysis)\n",
        "            continue\n",
        "\n",
        "        elif user_input.lower() == 'history':\n",
        "            print_history(chatbot)\n",
        "            continue\n",
        "\n",
        "        elif user_input.lower() == 'export':\n",
        "            filename = chatbot.export_conversation()\n",
        "            if COLORS_AVAILABLE:\n",
        "                print(Fore.GREEN + f\"\\nüíæ Conversation exported to: {filename}\")\n",
        "            else:\n",
        "                print(f\"\\nüíæ Conversation exported to: {filename}\")\n",
        "            continue\n",
        "\n",
        "        # Process normal message\n",
        "        bot_response, sentiment = chatbot.process_message(user_input)\n",
        "\n",
        "        # Display sentiment (TIER 2)\n",
        "        print_sentiment(sentiment)\n",
        "\n",
        "        # Display bot response\n",
        "        if COLORS_AVAILABLE:\n",
        "            print(Fore.GREEN + f\"\\nü§ñ Bot: {bot_response}\")\n",
        "        else:\n",
        "            print(f\"\\nü§ñ Bot: {bot_response}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "HxU3Jx2mFZL3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing**"
      ],
      "metadata": {
        "id": "VkNvzD_-7_ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# DEMO MODE (For Testing)\n",
        "# ===================================================================\n",
        "\n",
        "def run_demo():\n",
        "    \"\"\"Run demo with pre-set conversation\"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"  DEMO MODE - Showcasing All Features\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    chatbot = SentimentChatbot()\n",
        "\n",
        "    demo_messages = [\n",
        "        \"Your service disappoints me\",\n",
        "        \"Last experience was better\",\n",
        "        \"I'm having issues with the app\",\n",
        "        \"Actually, the support team was quite helpful\",\n",
        "        \"Thank you for addressing my concerns\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\nüé¨ Running demo conversation...\\n\")\n",
        "\n",
        "    for msg in demo_messages:\n",
        "        print(\"‚îÄ\" * 70)\n",
        "        print(f\"User: {msg}\")\n",
        "\n",
        "        bot_response, sentiment = chatbot.process_message(msg)\n",
        "        print_sentiment(sentiment)\n",
        "        print(f\"\\nü§ñ Bot: {bot_response}\\n\")\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"üìä FINAL CONVERSATION ANALYSIS (TIER 1):\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    analysis = chatbot.get_conversation_analysis()\n",
        "    print_analysis(analysis)\n",
        "\n",
        "    # Export demo\n",
        "    filename = chatbot.export_conversation(\"demo_conversation.json\")\n",
        "    print(f\"\\nüíæ Demo conversation exported to: {filename}\")\n"
      ],
      "metadata": {
        "id": "Qh_Fo54xFePe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XcNYCZyvFjB-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**use gradio**"
      ],
      "metadata": {
        "id": "qDVTCX5W8Eif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import json\n",
        "\n",
        "# -----------------------------------\n",
        "# Chatbot instance\n",
        "# -----------------------------------\n",
        "chatbot_instance = SentimentChatbot()\n",
        "\n",
        "# -----------------------------------\n",
        "# Sentiment badge (emoji + color logic)\n",
        "# -----------------------------------\n",
        "def sentiment_badge(label):\n",
        "    if label == \"Positive\":\n",
        "        return \" POSITIVE üòä\"\n",
        "    elif label == \"Negative\":\n",
        "        return \" NEGATIVE üòû\"\n",
        "    else:\n",
        "        return \" NEUTRAL üòê\"\n",
        "\n",
        "\n",
        "# -----------------------------------\n",
        "# Chat handler\n",
        "# -----------------------------------\n",
        "def gradio_chat(user_message, history):\n",
        "    if not user_message.strip():\n",
        "        return history, history\n",
        "\n",
        "    bot_reply, sentiment = chatbot_instance.process_message(user_message)\n",
        "    badge = sentiment_badge(sentiment.label)\n",
        "\n",
        "    history = history + [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"üë§ USER {badge}\\n{user_message}\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": f\"ü§ñ BOT üí¨\\n{bot_reply}\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    return history, history\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------------\n",
        "# Tier-1 conversation analysis\n",
        "# -----------------------------------\n",
        "def show_analysis():\n",
        "    analysis = chatbot_instance.get_conversation_analysis()\n",
        "    return json.dumps(analysis, indent=2)\n",
        "\n",
        "\n",
        "# -----------------------------------\n",
        "# Soft dark theme CSS (readable)\n",
        "# -----------------------------------\n",
        "soft_dark_css = \"\"\"\n",
        "body {\n",
        "    background: linear-gradient(135deg, #2b2f4b, #3a406a);\n",
        "}\n",
        "\n",
        ".gradio-container {\n",
        "    max-width: 900px !important;\n",
        "    margin: auto;\n",
        "    color: #f5f5f5 !important;\n",
        "}\n",
        "\n",
        ".markdown h1,\n",
        ".markdown h2,\n",
        ".markdown h3,\n",
        ".markdown p,\n",
        ".markdown strong {\n",
        "    color: #f5f5f5 !important;\n",
        "}\n",
        "\n",
        "/* Chat panel */\n",
        "#chatbot {\n",
        "    background-color: #f9fafb !important;\n",
        "    color: #111827 !important;\n",
        "    border-radius: 12px;\n",
        "    padding: 10px;\n",
        "}\n",
        "\n",
        "/* Message bubbles */\n",
        ".message.user {\n",
        "    background-color: #e0e7ff !important;\n",
        "    color: #111827 !important;\n",
        "}\n",
        "\n",
        ".message.bot {\n",
        "    background-color: #ecfeff !important;\n",
        "    color: #111827 !important;\n",
        "}\n",
        "\n",
        "/* Input box */\n",
        "textarea {\n",
        "    background-color: #ffffff !important;\n",
        "    color: #111827 !important;\n",
        "}\n",
        "\n",
        "/* Buttons */\n",
        "button {\n",
        "    border-radius: 8px !important;\n",
        "    font-weight: bold !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# -----------------------------------\n",
        "# Gradio UI\n",
        "# -----------------------------------\n",
        "with gr.Blocks(\n",
        "    title=\"üåà LiaPlus Sentiment Analysis Chatbot üåà\",\n",
        "    css=soft_dark_css\n",
        ") as demo:\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ü§ñ **L I A P L U S   C H A T B O T**\n",
        "\n",
        "    ### *Human-Like Chat ‚Ä¢ Sentiment Aware ‚Ä¢ Production Ready*\n",
        "\n",
        "     üòä**Positive** |  üòê**Neutral** | üòû**Negative**\n",
        "    ---\n",
        "    \"\"\")\n",
        "\n",
        "    chatbot_ui = gr.Chatbot(\n",
        "        height=420,\n",
        "        show_label=False,\n",
        "        elem_id=\"chatbot\"\n",
        "    )\n",
        "\n",
        "    state = gr.State([])\n",
        "\n",
        "    gr.Markdown(\" ***START CHATTING BELOW***\")\n",
        "\n",
        "    user_input = gr.Textbox(\n",
        "        placeholder=\"‚úçÔ∏è Type your message here...\",\n",
        "        label=\"üí¨ Your Message\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        send_btn = gr.Button(\"üöÄ SEND üí¨\")\n",
        "        analysis_btn = gr.Button(\"üìä ANALYSIS üìà\")\n",
        "        clear_btn = gr.Button(\"üßπ CLEAR üßΩ\")\n",
        "\n",
        "    gr.Markdown(\"__Sentiment Analysis__\")\n",
        "\n",
        "    analysis_output = gr.Code(\n",
        "        label=\"üìà Tier-1 Conversation Sentiment\",\n",
        "        language=\"json\"\n",
        "    )\n",
        "\n",
        "    # Button actions\n",
        "    send_btn.click(\n",
        "        gradio_chat,\n",
        "        inputs=[user_input, state],\n",
        "        outputs=[chatbot_ui, state]\n",
        "    ).then(\n",
        "        lambda: \"\",\n",
        "        None,\n",
        "        user_input\n",
        "    )\n",
        "\n",
        "    analysis_btn.click(\n",
        "        show_analysis,\n",
        "        outputs=analysis_output\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        lambda: ([], []),\n",
        "        None,\n",
        "        outputs=[chatbot_ui, state]\n",
        "    )\n",
        "\n",
        "demo.queue(False)\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "eaDAl0xsNRtZ",
        "outputId": "77144ae5-c971-414d-b37e-8e2077f5c17a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3926020251.py:112: UserWarning: The parameters have been moved from the Blocks constructor to the launch() method in Gradio 6.0: css. Please pass these parameters to launch() instead.\n",
            "  with gr.Blocks(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8fda92e5ea2b62888d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8fda92e5ea2b62888d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gradio huggingface_hub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f1ScJifkc65",
        "outputId": "0db45065-c846-4bff-ee53-806bc11c5e5e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (6.1.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (1.2.3)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==2.0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<13.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.4,>=2.11.10 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==2.0.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.5.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (0.20.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üöÄ Deploying LiaPlus Sentiment Analysis Chatbot on Hugging Face Spaces**"
      ],
      "metadata": {
        "id": "01fiiACs8PMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!hf auth login\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7aAusLBqqXD",
        "outputId": "2e15ff34-0d73-42c1-aacd-84c7e1e42802"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? [y/N]: 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\n",
            "Error: invalid input\n",
            "Add token as git credential? [y/N]: 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\n",
            "Error: invalid input\n",
            "Add token as git credential? [y/N]: y\n",
            "Token is valid (permission: write).\n",
            "The token `gradio-deploy` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Cannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `gradio-deploy`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHuys2ogth5s",
        "outputId": "53a08da5-8dc1-4970-d803-09ab9ebcb7df"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gradio deploy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lpL5lYiuTfa",
        "outputId": "ce485bc3-6c39-49ca-f3b0-7ae5a84422c4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Spaces Repo in '/content'. Collecting metadata, press Enter to \n",
            "accept default value.\n",
            "Enter Spaces app title [content]: ChatBot\n",
            "Enter Gradio app file : app.py\n",
            "Enter Spaces hardware (cpu-basic, cpu-upgrade, cpu-xl, zero-a10g, t4-small, t4-medium, l4x1, l4x4, l40sx1, l40sx4, l40sx8, a10g-small, a10g-large, a10g-largex2, a10g-largex4, a100-large, h100, h100x8) [cpu-basic]: cpu-basic\n",
            "Any Spaces secrets (y/n) [n]: n\n",
            "Create requirements.txt file? (y/n) [n]: y\n",
            "Enter a dependency (leave blank to end): gradio\n",
            "Enter a dependency (leave blank to end): nltk\n",
            "Enter a dependency (leave blank to end): colorama\n",
            "Enter a dependency (leave blank to end): \n",
            "Create Github Action to automatically update Space on 'git push'? [n]: n\n",
            "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            \n",
            "New Data Upload               : |          |  0.00B /  0.00B            \n",
            "\n",
            "  ...ata/mnist_train_small.csv:  46% 16.7M/36.5M [00:00<?, ?B/s]\n",
            "\n",
            "\n",
            "  ...ample_data/mnist_test.csv: 100% 18.3M/18.3M [00:00<?, ?B/s]\n",
            "\n",
            "  ...ata/mnist_train_small.csv:  46% 16.7M/36.5M [00:00<?, ?B/s]\n",
            "\n",
            "\n",
            "Processing Files (1 / 2)      :  64% 35.0M/54.8M [00:00<00:00, 60.4MB/s,  174MB/s  ]\n",
            "\n",
            "  ...ata/mnist_train_small.csv: 100% 36.5M/36.5M [00:00<00:00, 101MB/s]\n",
            "\n",
            "\n",
            "Processing Files (2 / 2)      : 100% 54.8M/54.8M [00:00<00:00, 73.8MB/s,  137MB/s  ]\n",
            "\n",
            "  ...ata/mnist_train_small.csv: 100% 36.5M/36.5M [00:00<00:00, 58.8MB/s]\n",
            "\n",
            "\n",
            "  ...ample_data/mnist_test.csv: 100% 18.3M/18.3M [00:00<?, ?B/s]\n",
            "\n",
            "  ...ata/mnist_train_small.csv: 100% 36.5M/36.5M [00:00<00:00, 50.2MB/s]\n",
            "\n",
            "\n",
            "Processing Files (2 / 2)      : 100% 54.8M/54.8M [00:00<00:00, 56.2MB/s, 91.4MB/s  ]\n",
            "New Data Upload               : |          |  0.00B /  0.00B,  0.00B/s  \n",
            "  ...ata/mnist_train_small.csv: 100% 36.5M/36.5M [00:00<00:00, 50.0MB/s]\n",
            "  ...ample_data/mnist_test.csv: 100% 18.3M/18.3M [00:00<?, ?B/s]\n",
            "Space available at https://huggingface.co/spaces/ShaliniDS13/ChatBot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CVTn9_9svTtb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}